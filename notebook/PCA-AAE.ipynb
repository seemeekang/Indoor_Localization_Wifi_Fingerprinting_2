{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class UJIDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, train = True, transform = None, target_transform = None, download = False):\n",
    "        self.root = root\n",
    "        dir_path = self.root + '/UJIndoorLoc'\n",
    "        zip_path = self.root + '/uji_uil.zip'\n",
    "        dataset_training_file = dir_path + '/trainingData.csv'\n",
    "        dataset_validation_file = dir_path + '/validationData.csv'\n",
    "        # Load independent variables (WAPs values)\n",
    "        if train:\n",
    "            dataset_file = dataset_training_file\n",
    "        else:\n",
    "            dataset_file = dataset_validation_file\n",
    "        file = open(dataset_file, 'r')\n",
    "        # Load independent variables\n",
    "        file_load = np.loadtxt(file, delimiter = ',', skiprows = 1)\n",
    "        self.x = file_load[:,0 : 520]\n",
    "        # Load dependent variables\n",
    "        self.y = file_load[:, 520:524]\n",
    "        file.close()\n",
    "        # Regularization of independent variables\n",
    "        self.x[self.x == 100] = -104    # WAP not detected\n",
    "        self.x = self.x + 104           # Convert into positive values\n",
    "        self.x = self.x / 104           # Regularize into scale between 0 and 1\n",
    "        # Reduce the number of dependent variables by combining building number and floor into one variable: area\n",
    "        self.y[:, 2] = self.y[:, 3] * 5 + self.y[:, 2]\n",
    "    def to_tensor(self):\n",
    "        self.x = torch.from_numpy(self.x).float()\n",
    "        self.y = torch.from_numpy(self.y).float()\n",
    "    # Return the target instance (row)\n",
    "    def __getitem__(self, index_row):\n",
    "        return self.x[index_row, :], self.y[index_row, :]\n",
    "    # Return the number of instances (the number of rows)\n",
    "    def __len__(self, dim = 0):\n",
    "        return int(self.x.size()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the training dataset (`trainingData.csv`) and the test dataset (`validationData.csv`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training dataset\n",
    "dataset_train = UJIDataset('./data', train = True)\n",
    "dataset_train.to_tensor()\n",
    "# Use only a part of trainingData.csv as a training set and the leftover as a validating set\n",
    "training_size = int(0.8 * len(dataset_train))\n",
    "indices = list(range(len(dataset_train)))\n",
    "train_indices, validate_indices = indices[:training_size], indices[training_size:]\n",
    "train_sampler = torch.utils.data.sampler.SubsetRandomSampler(train_indices)\n",
    "validate_sampler = torch.utils.data.sampler.SubsetRandomSampler(validate_indices)\n",
    "\n",
    "# Load test dataset\n",
    "dataset_test = UJIDataset('./data', train = False)\n",
    "dataset_test.to_tensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class `DelegateElectArea` is based on PCA.\n",
    "It will be used to predict the building and the floor with the given input of RSSI values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DelegateElectArea(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def train(self, x, y, delegate_num = 1):\n",
    "        self.x_train = x\n",
    "        self.y_train = y\n",
    "        self.delegate_num = delegate_num\n",
    "    # In this case, x_dim = 520 and y_range is within 0 and 15 (area)\n",
    "    def naive_delegate(self, x_dim, y_range):\n",
    "        # Construct weight_map of size y_range by x_dim\n",
    "        self.weight_map = torch.zeros([y_range, x_dim], dtype = torch.float64)\n",
    "        y_range_count = torch.ones([y_range])\n",
    "        if self.delegate_num is 1:\n",
    "            self.x_train_delegate_index = torch.argmax(self.x_train, dim = 1)\n",
    "            # Update weight_map\n",
    "            # Weight is 1\n",
    "            for i in range(0, self.x_train_delegate_index.size()[0]):\n",
    "                self.weight_map[int(self.y_train[i]), int(self.x_train_delegate_index[i])] += 1\n",
    "                y_range_count[int(self.y_train[i])] += 1\n",
    "            self.weight_map = self.weight_map / y_range_count[:, None]\n",
    "        else:\n",
    "            # Take all features that have non-zero values as delegates with corresponding weight (based on value)\n",
    "            # self.x_train_delegate = self.x_train, no need to make a duplicate\n",
    "            # Update weight_map\n",
    "            # Weight is the RSSI value\n",
    "            for i in range(0, self.x_train.size()[0]):\n",
    "                self.weight_map[int(self.y_train[i]), :] += self.x_train[i, :]\n",
    "                y_range_count[int(self.y_train[i])] += 1\n",
    "            self.weight_map = self.weight_map / y_range_count[:, None]\n",
    "    def softmax_delegate(self, x_dim, y_range):\n",
    "        # Construct weight_map of size y_range by x_dim\n",
    "        self.weight_map = torch.zeros([y_range, x_dim], dtype = torch.float64)\n",
    "        y_range_count = torch.ones([y_range])\n",
    "        softmax_row = torch.nn.Softmax(dim = 1)\n",
    "        softmax_log = torch.nn.LogSoftmax(dim = 1)\n",
    "        # Take all features that have non-zero values as delegates with corresponding weight (based on value)\n",
    "        # self.x_train_delegate = self.x_train, no need to make a duplicate\n",
    "        # Update weight_map\n",
    "        # Applying softmax function on RSSI values for each instance\n",
    "        for i in range(0, self.x_train.size()[0]):\n",
    "            self.weight_map[int(self.y_train[i]), :] += (self.x_train[i, :])\n",
    "            y_range_count[int(self.y_train[i])] += 1\n",
    "        self.weight_map = self.weight_map / y_range_count[:, None]\n",
    "        self.weight_map = softmax_row(self.weight_map)\n",
    "    def elect(self, x_input_instance):\n",
    "        # Calculate matrix multiplication of weight_map with x_input\n",
    "        candidate = torch.matmul(self.weight_map.float(), (x_input_instance * 104).float())\n",
    "        # Return the largest weight element's index from the candidate vector\n",
    "        return torch.argmax(candidate).item()\n",
    "    def evaluate(self, x_validate, y_validate):\n",
    "        error_building = []\n",
    "        error_floor = []\n",
    "        for i in range(0, x_validate.size()[0]):\n",
    "            prediction = self.elect(x_validate[i, :])\n",
    "            if prediction != y_validate[i, 2]:\n",
    "                error_floor.append(i)\n",
    "            if int(prediction / 5) != int(y_validate[i, 2] / 5):\n",
    "                error_building.append(i)\n",
    "        error_rate_building = len(error_building) / x_validate.size()[0]\n",
    "        error_rate_floor = len(error_floor) / x_validate.size()[0]\n",
    "        print('error_rate_building: ', error_rate_building)\n",
    "        print('error_rate_floor: ', error_rate_floor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error_rate_building:  0.0025075225677031092\n",
      "error_rate_floor:  0.18806419257773319\n"
     ]
    }
   ],
   "source": [
    "area_predictor = DelegateElectArea()\n",
    "area_predictor.train(dataset_train.x[0 : training_size, :], dataset_train.y[0 : training_size, 2], delegate_num = 0)\n",
    "area_predictor.softmax_delegate(x_dim = int(dataset_train.x.size()[1]), y_range = 15)\n",
    "# Cross validation\n",
    "area_predictor.evaluate(dataset_train.x[training_size : , :], dataset_train.y[training_size : ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `euclidean_distance` takes two coordinates and returns the distance between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Euclidean distance (unit: meter) between two coordinates in EPSG:3857 \n",
    "def euclidean_distance(latitude_1, longitude_1, latitude_2, longitude_2):\n",
    "    return np.sqrt((latitude_1 - latitude_2)**2 + (longitude_1 - longitude_2)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class `DelegateElectLocation` is based on PCA.\n",
    "It will be used to predict the location (latitude and longitude coordinates) with the given input of RSSI values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DelegateElectLocation():\n",
    "    def __init(self):\n",
    "        pass\n",
    "    def train(self, x, y, delegate_num = 1):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.delegate_num = delegate_num\n",
    "    def naive_delegate(self):\n",
    "        # Take the leftmost, rightmost, lowermost and uppermost grid coordinates from the training data\n",
    "        self.left_bound = self.y[torch.argmin(self.y[:, 0]).item(), 0].item()\n",
    "        self.right_bound = self.y[torch.argmax(self.y[:, 0]).item(), 0].item()\n",
    "        self.lower_bound = self.y[torch.argmin(self.y[:, 1]).item(), 1].item()\n",
    "        self.upper_bound = self.y[torch.argmax(self.y[:, 1]).item(), 1].item()\n",
    "        # Scale the coordinates to natural number of which the unit becomes (0.1m)\n",
    "        column_num = int((right_bound - left_bound) * 10) + 1\n",
    "        row_num = int((upper_bound - lower_bound) * 10) + 1\n",
    "        # Construct the coordinates mapping matrix\n",
    "        self.coordinate_map = torch.zeros([row_num, column_num], dtype = torch.float64)\n",
    "        # Construct the correlation matrix of (longitude by RSSI values) and (latitude by RSSI values)\n",
    "        self.longitude_weight_map = torch.zeros([column_num, self.x.size()[1]], dtype = torch.float64)\n",
    "        self.latitude_weight_map = torch.zeros([row_num, self.x.size()[1]], dtype = torch.float64)\n",
    "        longitude_count = torch.ones([column_num])\n",
    "        latitude_count = torch.ones([row_num])\n",
    "        # If we take only one representative (largest) element of each independent instance\n",
    "        if self.delegate_num is 1:\n",
    "            delegate_index = torch.argmax(self.x, dim = 1)\n",
    "            for i in range(delegate_index.size()[0]):\n",
    "                self.longitude_weight_map[int((self.y[i, 0] - self.left_bound) * 10), int(delegate_index[i])] += 1\n",
    "                self.latitude_weight_map[int((self.y[i, 1] - self.lower_bound) * 10), int(delegate_index[i])] += 1\n",
    "                longitude_count[int((self.y[i, 0] - self.left_bound) * 10)] += 1\n",
    "                latitude_count[int((self.y[i, 1] - self.lower_bound) * 10)] += 1\n",
    "                self.coordinate_map[int((self.y[i, 1] - self.lower_bound) * 10), int((self.y[i, 0] - self.left_bound) * 10)] += 1\n",
    "        # If we take all elements of each independent instance with their corresponding weights\n",
    "        else:\n",
    "            for i in range(self.x.size()[0]):\n",
    "                self.longitude_weight_map[int((self.y[i, 0] - self.left_bound) * 10), :] += self.x[i, :]\n",
    "                self.latitude_weight_map[int((self.y[i, 1] - self.lower_bound) * 10), :] += self.x[i, :]\n",
    "                longitude_count[int((self.y[i, 0] - self.left_bound) * 10)] += 1\n",
    "                latitude_count[int((self.y[i, 1] - self.lower_bound) * 10)] += 1\n",
    "                self.coordinate_map[int((self.y[i, 1] - self.lower_bound) * 10), int((self.y[i, 0] - self.left_bound) * 10)] += 1\n",
    "        # Take means of each row of weight maps with corresponding counts\n",
    "        self.longitude_weight_map /= longitude_count[:, None]\n",
    "        self.latitude_weight_map /= latitude_count[:, None]\n",
    "    # Same as naive_delegate function except that softmax_delegate function applies softmax function to the output weight maps\n",
    "    def softmax_delegate(self):\n",
    "        self.left_bound = self.y[torch.argmin(self.y[:, 0]).item(), 0].item()\n",
    "        self.right_bound = self.y[torch.argmax(self.y[:, 0]).item(), 0].item()\n",
    "        self.lower_bound = self.y[torch.argmin(self.y[:, 1]).item(), 1].item()\n",
    "        self.upper_bound = self.y[torch.argmax(self.y[:, 1]).item(), 1].item()\n",
    "        column_num = int((self.right_bound - self.left_bound) * 10) + 1\n",
    "        row_num = int((self.upper_bound - self.lower_bound) * 10) + 1\n",
    "        self.coordinate_map = torch.zeros([row_num, column_num], dtype = torch.float64)\n",
    "        self.longitude_weight_map = torch.zeros([column_num, self.x.size()[1]], dtype = torch.float64)\n",
    "        self.latitude_weight_map = torch.zeros([row_num, self.x.size()[1]], dtype = torch.float64)\n",
    "        longitude_count = torch.ones([column_num])\n",
    "        latitude_count = torch.ones([row_num])\n",
    "        softmax_row = torch.nn.Softmax(dim = 1)\n",
    "        softmax_log = torch.nn.LogSoftmax(dim = 1)\n",
    "        # Take all features that have non-zero values as delegates with corresponding weight (based on value)\n",
    "        # self.x_train_delegate = self.x_train, no need to make a duplicate\n",
    "        # Update weight_map\n",
    "        for i in range(self.x.size()[0]):\n",
    "            self.longitude_weight_map[int((self.y[i, 0] - self.left_bound) * 10), :] += self.x[i, :]\n",
    "            self.latitude_weight_map[int((self.y[i, 1] - self.lower_bound) * 10), :] += self.x[i, :]\n",
    "            longitude_count[int((self.y[i, 0] - self.left_bound) * 10)] += 1\n",
    "            latitude_count[int((self.y[i, 1] - self.lower_bound) * 10)] += 1\n",
    "            self.coordinate_map[int((self.y[i, 1] - self.lower_bound) * 10), int((self.y[i, 0] - self.left_bound) * 10)] += 1\n",
    "        self.longitude_weight_map /= longitude_count[:, None]\n",
    "        self.latitude_weight_map /= latitude_count[:, None]\n",
    "        # Applying softmax function on RSSI values for each instance\n",
    "        self.longitude_weight_map = softmax_row(self.longitude_weight_map)\n",
    "        self.latitude_weight_map = softmax_row(self.latitude_weight_map)\n",
    "    def elect(self, x_input_instance):\n",
    "        # Calculate matrix multiplication of weight_map with transpose of x_input\n",
    "        longitude_candidate = torch.matmul(self.longitude_weight_map.float(), (x_input_instance * 104).float())\n",
    "        latitude_candidate = torch.matmul(self.latitude_weight_map.float(), (x_input_instance * 104).float())\n",
    "        # Return the largest weight element's index from the candidate vector\n",
    "        return torch.argmax(latitude_candidate).item(), torch.argmax(longitude_candidate).item()\n",
    "    def evaluate(self, x_validate, y_validate):\n",
    "        error_distance = []\n",
    "        for i in range(0, x_validate.size()[0]):\n",
    "            latitude_prediction, longitude_prediction = self.elect(x_validate[i, :])\n",
    "            # Rescale back to the original pseudo-mercator coordinates\n",
    "            latitude_prediction = latitude_prediction / 10 + self.lower_bound\n",
    "            longitude_prediction = longitude_prediction / 10 + self.left_bound\n",
    "            # Push back the errors based on euclidean distance (unit: meter) for each prediction\n",
    "            error_distance.append(euclidean_distance(y_validate[i, 1], y_validate[i, 0], latitude_prediction, longitude_prediction))\n",
    "        # Take mean, max, min of all errors of distance\n",
    "        error_mean_distance = torch.mean(torch.stack(error_distance)).item()\n",
    "        error_max_distance = torch.max(torch.stack(error_distance)).item()\n",
    "        error_min_distance = torch.min(torch.stack(error_distance)).item()\n",
    "        error_std_distance = torch.std(torch.stack(error_distance)).item()\n",
    "        error_var_distance = torch.var(torch.stack(error_distance)).item()\n",
    "        print('error_mean_distance: ', error_mean_distance)\n",
    "        print('error_max_distance: ', error_max_distance)\n",
    "        print('error_min_distance: ', error_min_distance)\n",
    "        print('error_std_distance: ', error_std_distance)\n",
    "        print('error_var_distance: ', error_var_distance)\n",
    "        #print('error_distance: ', error_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error_mean_distance:  15.561348915100098\n",
      "error_max_distance:  252.39747619628906\n",
      "error_min_distance:  0.00634765625\n",
      "error_std_distance:  16.111896514892578\n",
      "error_var_distance:  259.5932312011719\n"
     ]
    }
   ],
   "source": [
    "location_predictor = DelegateElectLocation()\n",
    "location_predictor.train(dataset_train.x[0:training_size, :], dataset_train.y[0:training_size, :], delegate_num = 0)\n",
    "location_predictor.softmax_delegate()\n",
    "# Cross validation\n",
    "location_predictor.evaluate(dataset_train.x[training_size :, :], dataset_train.y[training_size :, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The real test with `validationData.csv` is as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error_rate_building:  0.0009000900090009\n",
      "error_rate_floor:  0.15031503150315031\n"
     ]
    }
   ],
   "source": [
    "area_predictor = DelegateElectArea()\n",
    "area_predictor.train(dataset_train.x, dataset_train.y[:, 2], delegate_num = 0)\n",
    "area_predictor.softmax_delegate(x_dim = int(dataset_train.x.size()[1]), y_range = 15)\n",
    "# Test (real validation)\n",
    "area_predictor.evaluate(dataset_test.x, dataset_test.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error_mean_distance:  13.55756664276123\n",
      "error_max_distance:  92.46202087402344\n",
      "error_min_distance:  0.0302734375\n",
      "error_std_distance:  10.330753326416016\n",
      "error_var_distance:  106.72445678710938\n"
     ]
    }
   ],
   "source": [
    "location_predictor = DelegateElectLocation()\n",
    "location_predictor.train(dataset_train.x, dataset_train.y, delegate_num = 0)\n",
    "location_predictor.softmax_delegate()\n",
    "# Test (real validation)\n",
    "location_predictor.evaluate(dataset_test.x, dataset_test.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.)\n",
      "tensor(7.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1549d12e748>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(dataset_train.y[0, 2])\n",
    "print(dataset_train.y[1, 2])\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(dataset_train.x[0, :])\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(dataset_train.x[1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following networks are for semi-supervised AAE (Adversarial Auto-Encoder), which needs more implementations.\n",
    "It does not work at the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Encoder (Generator)\n",
    "class NetQ(torch.nn.Module):\n",
    "    def __init__(self, p = 0.0):\n",
    "        super(NetQ, self).__init__()\n",
    "        # global variables: x_dim = 520, y_dim = 2, h = 1000, z_dim = 5 \n",
    "        self.lin_1_x = torch.nn.Linear(x_dim, h)\n",
    "        self.lin_2_x = torch.nn.Linear(h, h)\n",
    "        self.lin_3_gaussian = torch.nn.Linear(h, z_dim)\n",
    "        self.lin_1_y = torch.nn.Linear(y_dim, h)\n",
    "        self.lin_2_y = torch.nn.Linear(h, h)\n",
    "        self.lin_3_regressive = torch.nn.Linear(h, y_dim)\n",
    "        self.p = p\n",
    "    # For Semi-supervised learning, y is added as an optional parameter\n",
    "    def forward(self, x, y = None):\n",
    "        #x = torch.nn.functional.dropout(self.lin_1_x(x), p = self.p, training = self.training)\n",
    "        x = self.lin_1_x(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        #x = torch.nn.functional.dropout(self.lin_2_x(x), p = self.p, training = self.training)\n",
    "        x = self.lin_2_x(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        z = self.lin_3_gaussian(x)\n",
    "        if y is not None:\n",
    "            #y = torch.nn.functional.dropout(self.lin_1_y(y), p = self.p, training = self.training)\n",
    "            y = self.lin_1_y(y)\n",
    "            y = torch.nn.functional.relu(y)\n",
    "            #y = torch.nn.functional.dropout(self.lin_2_y(y), p = self.p, training = self.training)\n",
    "            y = self.lin_2_y(y)\n",
    "            y = torch.nn.functional.relu(y)\n",
    "            y_fake = self.lin_3_regressive(y)\n",
    "            return z, y_fake\n",
    "        else:\n",
    "            return z\n",
    "    \n",
    "# Decoder \n",
    "class NetP(torch.nn.Module):\n",
    "    def __init__(self, p = 0.0):\n",
    "        super(NetP, self).__init__()\n",
    "        # global variables: x_dim = 520, y_dim = 2, h = 1000, z_dim = 5 \n",
    "        self.lin_1 = torch.nn.Linear(z_dim, h)\n",
    "        self.lin_2 = torch.nn.Linear(h, h)        \n",
    "        self.lin_3 = torch.nn.Linear(h, x_dim)\n",
    "        self.p = p\n",
    "    # For Semi-supervised learning, y is added as an optional parameter\n",
    "    def forward(self, x, y = None):\n",
    "        if y is not None:\n",
    "            x = torch.cat([x, y], 1)\n",
    "        #x = torch.nn.functional.dropout(self.lin_1(x), p = self.p, training = self.training)\n",
    "        x = self.lin_1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        #x = torch.nn.functional.dropout(self.lin_2(x), p = self.p, training = self.training)\n",
    "        x = self.lin_2(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        return self.lin_3(x)\n",
    "    \n",
    "# Gaussian Discriminator\n",
    "class NetDGaussian(torch.nn.Module):\n",
    "    def __init__(self, p = 0.0):\n",
    "        super(NetDGaussian, self).__init__()\n",
    "        # global variables: h = 1000, z_dim = 5 \n",
    "        self.lin_1 = torch.nn.Linear(z_dim, h)\n",
    "        self.lin_2 = torch.nn.Linear(h, h)\n",
    "        self.lin_3 = torch.nn.Linear(h, 1)\n",
    "        self.p = p\n",
    "    def forward(self, x):\n",
    "        #x = torch.nn.functional.dropout(self.lin_1(x), p = self.p, training = self.training)\n",
    "        x = self.lin_1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        #x = torch.nn.functional.dropout(self.lin_2(x), p = self.p, training = self.training)\n",
    "        x = self.lin_2(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        return torch.softmax(self.lin_3(x), dim = 1)\n",
    "        \n",
    "# Regressive Discriminator\n",
    "class NetDRegressive(torch.nn.Module):\n",
    "    # parameter d represents distance criterion\n",
    "    def __init__(self, p = 0.0, d = 0.0):\n",
    "        super(NetDRegressive, self).__init__()\n",
    "        # global variables: y_dim = 2, h = 1000, z_dim = 5 \n",
    "        self.lin_1 = torch.nn.Linear(y_dim, h)\n",
    "        self.lin_2 = torch.nn.Linear(h, h)\n",
    "        self.lin_3 = torch.nn.Linear(h, 1)\n",
    "        self.p = p\n",
    "    def forward(self, x):\n",
    "        #x = torch.nn.functional.dropout(self.lin_1(x), p = self.p, training = self.training)\n",
    "        x = self.lin_1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        #x = torch.nn.functional.dropout(self.lin_2(x), p = self.p, training = self.training)\n",
    "        x = self.lin_2(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        return torch.softmax(self.lin_3(x), dim = 1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dimensions and parameters\n",
    "x_dim = dataset_train.x.size()[1]    # 520\n",
    "y_dim = 2                      # longitude and latitude\n",
    "z_dim = 5                      # latent variable dimension\n",
    "h = 1000                       # hidden layer dimension\n",
    "batch_size = 200\n",
    "n_epochs = 100\n",
    "\n",
    "torch.manual_seed(10)\n",
    "# Construct network layers\n",
    "Q = NetQ(p = 0.0)                  # Encoder (Generator)\n",
    "P = NetP(p = 0.0)                  # Decoder\n",
    "DG = NetDGaussian(p = 0.0)          # Discriminator adversarial\n",
    "DR = NetDRegressive(p = 0.0, d = 1) # Discriminator regressive\n",
    "# Activate CUDA if available\n",
    "if torch.cuda.is_available():\n",
    "    P = P.cuda()\n",
    "    Q = Q.cuda()\n",
    "    DG = DG.cuda()\n",
    "    DR = DR.cuda()\n",
    "# Set learning rate\n",
    "gen_lr, reg_lr = 0.0006, 0.0008\n",
    "# Set optimizers\n",
    "Q_encoder = torch.optim.Adam(Q.parameters(), lr = gen_lr)\n",
    "Q_generator = torch.optim.Adam(Q.parameters(), lr = reg_lr)\n",
    "P_decoder = torch.optim.Adam(P.parameters(), lr = gen_lr)\n",
    "DG_solver = torch.optim.Adam(DG.parameters(), lr = reg_lr)\n",
    "DR_solver = torch.optim.Adam(DR.parameters(), lr = reg_lr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
